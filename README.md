# HMD Births Heatmaps

Interactive visualization of birth seasonality patterns using data from the Human Mortality Database and UN Population Division.

## Project Structure

```
hmd-births-heatmaps/
├── data-pipeline/          # Python data preparation
│   ├── src/
│   │   ├── config/         # Settings and country definitions
│   │   ├── loaders/        # HMD, UN, Japan data loaders
│   │   ├── processors/     # Interpolation, fertility, seasonality
│   │   ├── exporters/      # JSON and CSV export
│   │   └── schemas/        # Pandera data validation
│   ├── scripts/            # Entry point scripts
│   ├── notebooks/          # Jupyter notebooks for exploration
│   ├── output/             # Generated data (git-ignored)
│   ├── environment.yml     # Conda environment
│   └── Dockerfile
├── frontend/               # Astro static site
│   ├── src/
│   │   ├── assets/data/    # JSON data for Vite imports (generated by pipeline)
│   │   ├── components/     # D3 heatmap components
│   │   ├── pages/          # Astro pages
│   │   └── lib/            # TypeScript utilities
│   └── public/             # Static assets (favicon, etc.)
├── docker-compose.yml
└── Makefile
```

## Data Sources

- **Human Mortality Database (HMD)**: Monthly births and population data for 41+ countries
  - https://www.mortality.org/
- **UN World Population Prospects**: Supplementary population data
  - https://population.un.org/wpp/
- **Japan Population Data**: Via fmsb R package

> **Note**: Raw data files are not included in this repository per license terms from data providers. You must download them manually from the sources above.

## Quick Start

### Prerequisites

- Docker and Docker Compose
- Node.js 18+ (for frontend development)

### Running with Docker

```bash
# Start Jupyter notebook server for data exploration
docker compose up jupyter

# Run the data pipeline (generates JSON files)
docker compose run pipeline

# Start frontend development server
docker compose up frontend-dev
```

### Local Development (without Docker)

#### Data Pipeline

```bash
cd data-pipeline

# Create conda environment
conda env create -f environment.yml
conda activate hmd-pipeline

# Run pipeline
python scripts/run_pipeline.py
```

#### Frontend

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

## Data Loading Pattern

**IMPORTANT**: This project follows best practices for loading JSON data in Astro/Vite projects.

### Rules for JSON Data Files

1. **ALWAYS place JSON data files in `frontend/src/assets/data/`** - This allows Vite to:
   - Cache-bust files with content hashes
   - Optimize and bundle them properly
   - Track dependencies correctly

2. **NEVER load data from `public/` directory using fetch()** - The `public/` directory is only for:
   - Files that need exact URLs (like `robots.txt`, `favicon.ico`)
   - Files that should NOT be processed by the build system
   - Static assets referenced by absolute paths

3. **Use proper ES module imports**:
   ```typescript
   // ✅ CORRECT - Import from src/assets
   import countriesData from '../assets/data/countries.json';

   // ✅ CORRECT - Use import.meta.glob for dynamic imports
   const files = import.meta.glob<T>('../../assets/data/fertility/*.json');

   // ❌ WRONG - Don't use fetch from public/
   fetch('/data/countries.json')  // DON'T DO THIS

   // ❌ WRONG - Don't use Node.js fs operations
   fs.readFile('./public/data/countries.json')  // DON'T DO THIS
   ```

### Data Pipeline Integration

The data pipeline automatically exports JSON files to **both** locations:
- `data-pipeline/output/` - For nginx serving in production
- `frontend/src/assets/data/` - For Vite imports in the frontend (PREFERRED)

When you run the pipeline, data is written to both locations automatically.

## Metrics

The pipeline computes several fertility and seasonality metrics:

- **Daily Fertility Rate**: Births per 100,000 women age 15-44
- **Seasonality Ratio**: Ratio to 12-month moving average
- **Seasonality Percentage**: Percentage of annual births per month (normalized to 30-day months)

## Development Status

- [x] Stage A: Repository infrastructure
- [x] Stage B: Python pipeline refactoring
- [x] Stage C: Astro frontend initialization
- [ ] Stage D: D3 heatmap components
- [ ] Stage E: Integration and testing

## Pipeline Usage

### Development Entry Point

**Recommended:** Use the VSCode debug configuration **"Python: Run Pipeline (JSON + Charts)"** which generates all outputs needed for development.

Or run from command line:
```bash
# JSON + Charts (recommended for development)
python data-pipeline/scripts/run_pipeline.py --json --charts

# JSON only (fastest, for frontend development)
python data-pipeline/scripts/run_pipeline.py --json

# Charts only
python data-pipeline/scripts/run_pipeline.py --charts

# Everything including legacy CSV files
python data-pipeline/scripts/run_pipeline.py --all
```

See [data-pipeline/README.md](data-pipeline/README.md) for detailed documentation on pipeline outputs and architecture.

## Testing

### Data Pipeline Tests (Python)

```bash
cd data-pipeline

# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest tests/test_config.py
```

Test modules:
- `tests/test_config.py` - Configuration and country definitions
- `tests/test_processors.py` - Data interpolation, fertility, seasonality
- `tests/test_exporters.py` - JSON export validation

### Frontend Tests (TypeScript)

```bash
cd frontend

# Run all tests
npm test

# Run in watch mode
npm run test:watch
```

Test modules:
- `src/lib/types.test.ts` - TypeScript interface validation
- `src/lib/data.test.ts` - Data loading utilities

## Documentation

- [CHANGELOG.md](CHANGELOG.md) - Detailed progress at each development stage
- [CHART_LOADING.md](CHART_LOADING.md) - How chart images are loaded in the frontend
- [data-pipeline/README.md](data-pipeline/README.md) - Pipeline architecture and outputs
